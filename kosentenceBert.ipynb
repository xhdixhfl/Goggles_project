{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44eefba-7490-4b49-ab68-2a587a9e4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ko-sentence-transformers\n",
      "  Downloading ko_sentence_transformers-0.3.tar.gz (11 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Anaconda3\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-caouzmzl\\\\ko-sentence-transformers_6071a109e1c84e9d9504e6075e72bc24\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-caouzmzl\\\\ko-sentence-transformers_6071a109e1c84e9d9504e6075e72bc24\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-pip-egg-info-kfa8wqu4'\n",
      "         cwd: C:\\Users\\admin\\AppData\\Local\\Temp\\pip-install-caouzmzl\\ko-sentence-transformers_6071a109e1c84e9d9504e6075e72bc24\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\admin\\AppData\\Local\\Temp\\pip-install-caouzmzl\\ko-sentence-transformers_6071a109e1c84e9d9504e6075e72bc24\\setup.py\", line 6, in <module>\n",
      "        long_description = f.read()\n",
      "    UnicodeDecodeError: 'cp949' codec can't decode byte 0xec in position 30: illegal multibyte sequence\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/f2/a8/7dbd819a5aa71c0afd54c0c7764d78106aa222a2601f9011e63e228dd2d5/ko_sentence_transformers-0.3.tar.gz#sha256=fe22504d6bf54634bea6c418ceb7e7572b33caf2f73e92a595ccab456e1bc8f4 (from https://pypi.org/simple/ko-sentence-transformers/) (requires-python:>=3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading ko_sentence_transformers-0.2.tar.gz (8.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from sentence-transformers->ko-sentence-transformers) (4.62.3)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from sentence-transformers->ko-sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (from sentence-transformers->ko-sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from sentence-transformers->ko-sentence-transformers) (1.9.3)\n",
      "Requirement already satisfied: nltk in c:\\anaconda3\\lib\\site-packages (from sentence-transformers->ko-sentence-transformers) (3.6.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (21.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers->ko-sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->ko-sentence-transformers) (2021.8.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: click in c:\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers->ko-sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers->ko-sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->ko-sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers->ko-sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers->ko-sentence-transformers) (8.4.0)\n",
      "Building wheels for collected packages: ko-sentence-transformers, sentence-transformers\n",
      "  Building wheel for ko-sentence-transformers (setup.py): started\n",
      "  Building wheel for ko-sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for ko-sentence-transformers: filename=ko_sentence_transformers-0.2-py3-none-any.whl size=7539 sha256=0c3459c256dfc0b528171b82fedcf89e04b7e4f7eb60c05a5a8dad7ad6cdf591\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\db\\e7\\77\\a61e2d35160510738d50fe4e3ab2bf79817b93597d45c51cd0\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=0938bc7f2a5cad708b5fa7f555f5209c95afa8ea6edb98a384be2dea0c7d3b5c\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built ko-sentence-transformers sentence-transformers\n",
      "Installing collected packages: torch, tokenizers, huggingface-hub, transformers, torchvision, sentencepiece, sentence-transformers, ko-sentence-transformers\n",
      "Successfully installed huggingface-hub-0.12.0 ko-sentence-transformers-0.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ko-sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad14c4df-c96f-4da4-8761-0e83b13fd496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3a8714bd474648bbf8f44a5f9c4d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470377d6cc5041f39755e8539935d315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e73f20cd106458bbc3cde4678d6f13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)zer_78b3253a26.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d372e10b56f7472fad8968a6d90f2095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e386f26987e4dc5937c86a52574d65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from ko_sentence_transformers.models import KoBertTransformer\n",
    "word_embedding_model = KoBertTransformer(\"monologg/kobert\", max_seq_length=75)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f7927f-a5b9-48d5-8fda-89b6b70729da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5309dce04146d980681dbcb62cee6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d27b2/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eba3e0c37fc428684aa0fd2cad7ab66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4d692d0df942f8821c7ccfcfbc21fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2bc2fd27b2/README.md:   0%|          | 0.00/4.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df34db0c0b45426f93f29300fe9a3740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c2fd27b2/config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908b7c442283434e922ae6874c7c88f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2e3718f1394e37b9109a9d9702aa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_sts-dev_results.csv:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013508c0068145739843f9ae2ede83b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ab1dfc56dc42a787dcb0bea99144e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dcc9f45a88442791ab889110ae6537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)sts-test_results.csv:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226da1c244634d3ca5e92ed6722154ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9fb4642ab946d9b5ab14e09ec24ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d27b2/tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5c91e49dcb4ba7b070f0d8bee65c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2190b9e2a247dbb4f56201e11e075d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2bc2fd27b2/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45744f3ec59402d98fde978844edeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2fd27b2/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 한 남자가 파스타를 먹는다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "한 남자가 음식을 먹는다. (Score: 0.6154)\n",
      "한 남자가 빵 한 조각을 먹는다. (Score: 0.5451)\n",
      "한 여자가 바이올린을 연주한다. (Score: 0.0980)\n",
      "한 남자가 말을 탄다. (Score: 0.0686)\n",
      "한 남자가 담으로 싸인 땅에서 백마를 타고 있다. (Score: 0.0572)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "원숭이 한 마리가 드럼을 연주한다. (Score: 0.7253)\n",
      "치타 한 마리가 먹이 뒤에서 달리고 있다. (Score: 0.1940)\n",
      "한 여자가 바이올린을 연주한다. (Score: 0.1483)\n",
      "한 남자가 담으로 싸인 땅에서 백마를 타고 있다. (Score: 0.0471)\n",
      "한 남자가 음식을 먹는다. (Score: 0.0082)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 치타가 들판을 가로 질러 먹이를 쫓는다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "치타 한 마리가 먹이 뒤에서 달리고 있다. (Score: 0.7887)\n",
      "원숭이 한 마리가 드럼을 연주한다. (Score: 0.3887)\n",
      "두 남자가 수레를 숲 속으로 밀었다. (Score: 0.1610)\n",
      "한 남자가 음식을 먹는다. (Score: 0.0739)\n",
      "그 여자가 아이를 돌본다. (Score: 0.0568)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer(\"jhgan/ko-sbert-sts\")\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['한 남자가 음식을 먹는다.',\n",
    "          '한 남자가 빵 한 조각을 먹는다.',\n",
    "          '그 여자가 아이를 돌본다.',\n",
    "          '한 남자가 말을 탄다.',\n",
    "          '한 여자가 바이올린을 연주한다.',\n",
    "          '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "          '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    "          '원숭이 한 마리가 드럼을 연주한다.',\n",
    "          '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['한 남자가 파스타를 먹는다.',\n",
    "           '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "           '치타가 들판을 가로 질러 먹이를 쫓는다.']\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8da08a9-b7f3-4c87-a062-73d7fddc35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 얼른 많은 분들이 사용해보셨으면 하는 마음입니다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "이제품 너무 마음에 들어서 추천하고 싶다. (Score: 0.3566)\n",
      "나도 이걸 사야지. (Score: 0.3479)\n",
      "테스트 해봤는데 정말 촉촉하고 피부에 흡수도 잘 되고 마무리감이 좋다. (Score: 0.3029)\n",
      "밤에 잘 때 듬뿍은 아니어도 한번 발라주고 그 위에 펴발라주고 잔다. (Score: 0.2757)\n",
      "원숭이 한 마리가 립스틱을 가져갔다. (Score: 0.2122)\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = ['테스트 해봤는데 정말 촉촉하고 피부에 흡수도 잘 되고 마무리감이 좋다.',\n",
    "          ' 밤에 잘 때 듬뿍은 아니어도 한번 발라주고 그 위에 펴발라주고 잔다.',\n",
    "          '이제품 너무 마음에 들어서 추천하고 싶다.',\n",
    "          '그 여자는 화장품을 산다.',\n",
    "          '아빠한테 화장품을 선물해드릴것이다.',\n",
    "          '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "          '나도 이걸 사야지.',\n",
    "          '원숭이 한 마리가 립스틱을 가져갔다.',\n",
    "          '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['얼른 많은 분들이 사용해보셨으면 하는 마음입니다.']\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae05a421-bb6d-4d10-ab5b-c8e9727ac8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T08:24:33.019555Z",
     "start_time": "2023-02-02T08:24:32.828084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.6\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f1b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
